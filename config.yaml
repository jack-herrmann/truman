# Intuition — AI Personality Engine Configuration

# ── LLM Provider ──────────────────────────────────────────────────────
# Free-tier options (no credit card required):
#   provider: gemini   →  GEMINI_API_KEY  (1500 req/day on gemini-2.0-flash)
#   provider: groq     →  GROQ_API_KEY    (OpenAI-compatible, llama-3.3-70b)
# NVIDIA NeMo / NIM (self-hosted or NGC):
#   provider: nemo     →  NIM_PROXY_BASE_URL (e.g. http://localhost:8000), optional NIM_API_KEY
#   or set llm.base_url / llm.nemo.base_url instead of env
# Paid options:
#   provider: anthropic → ANTHROPIC_API_KEY
#   provider: openai    → OPENAI_API_KEY
llm:
  provider: gemini
  model: gemini-2.0-flash
  max_tokens: 4096
  temperature: 0.7
  # base_url: http://localhost:8000   # for provider: nemo
  # nemo:
  #   base_url: http://localhost:8000

embeddings:
  provider: local  # "openai" for production, "local" for dev (free, no API key)
  model: text-embedding-3-small
  dimension: 512

latent:
  dimension: 32
  hidden_dims: [512, 256]
  epochs: 200
  learning_rate: 0.001
  kl_weight: 0.001

training:
  population_size: 12
  num_generations: 10
  episode_length: 12
  coherence_weight: 0.5
  individuality_weight: 0.5
  elite_fraction: 0.25
  mutation_radius: 0.3

evaluation:
  probe_repetitions: 3
  eval_episode_length: 8

corpus:
  novels_dir: data/novels
  characters_dir: data/characters
  # Use Bright Data for downloads (set USE_BRIGHTDATA=1 or script --brightdata; needs BRIGHTDATA_API_TOKEN)
  # use_brightdata: false

paths:
  novels: data/novels
  characters: data/characters
  checkpoints: data/checkpoints
  reports: data/reports
